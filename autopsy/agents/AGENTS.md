<!-- generated by autopsy -->
# Review Agents

## Purpose
Agent definition files for the 7 specialized sub-agents used in autopsy. Each agent has a specific domain expertise and produces findings in a standardized format.

## Key Files
| File | Purpose | Key Exports |
|------|---------|-------------|
| `discovery.md` | Phase 1 repo mapper | Generates batch plan, creates AGENTS.md files |
| `bug-hunter.md` | Logic error detector | Finds off-by-one, null access, race conditions |
| `security-auditor.md` | Security vuln scanner | Finds injection, auth issues, secrets |
| `error-inspector.md` | Error handling analyzer | Finds missing try/catch, empty catch, missing timeouts |
| `performance-detector.md` | Performance issue finder | Finds N+1 queries, memory leaks, unbounded ops |
| `stack-reviewer.md` | Stack-specific linter | Applies framework/language best practices |
| `synthesizer.md` | Phase 3 merger | Deduplicates findings, writes final report |

## Data Flow
Orchestrator reads batch plan → creates batch-N directory → launches 5 review agents (bug/security/error/perf/stack) as parallel foreground Task calls with batch assignment → agents read AGENTS.md context → agents read full file contents → agents write findings to batch-N/*.md → orchestrator verifies output files → synthesizer reads all batch-*/ findings → deduplicates → writes REVIEW_REPORT.md

## Dependencies
- Internal: Cross-cutting.md v1 (finding format, self-review pattern)
- External: Built-in tools only (Read, Grep, Glob, Bash where applicable)

## Patterns & Conventions
- Every agent starts with YAML frontmatter (name, description, tools)
- Every review agent includes exhaustive checklist of what to check
- 2-3 few-shot examples per agent (concrete findings in exact format)
- Self-review checklist at end (verifies completeness before finishing)
- Confidence scoring (High/Medium/Low) based on evidence strength
- Line count targets: discovery ~355 lines, review agents ~160 lines, synthesizer ~306 lines

## Configuration
No runtime config. Agent behavior is defined entirely in the .md files. Orchestrator passes batch assignments via Task tool prompt parameter.

## Gotchas
- Agents run in isolated contexts — no shared state except via disk
- Few-shot examples are critical for quality (without them, agents say "looks fine" too often)
- Self-review step must be explicit — agents won't verify output unless told
- Discovery agent writes to root AGENTS.md; review agents only update module AGENTS.md if they find undocumented gotchas
- Stack-reviewer adapts checks based on discovered tech stack (reads root AGENTS.md)

## Testing
- Tests: Manual verification via full review runs on test repos
- Run: Invoke parent orchestrator command
- Gaps: Individual agents cannot be tested in isolation (no direct agent invocation API)

## Boundaries
- **Always:** Include complete checklists (don't abbreviate)
- **Always:** Include 2-3 few-shot examples per review agent
- **Ask first:** Changing finding format (breaks synthesizer parsing)
- **Never:** Remove self-review checklist
- **Never:** Exceed 400 lines per agent file
